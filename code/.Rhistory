edges <- read.csv("../data/GOT-edges.csv")
head(edges)
nrow(edges)
nodes <- read.csv("../data/GOT-nodes.csv")
head(nodes)
nrow(nodes)
edges <- read.csv("../data/stormofswords.csv")
str(edges)
edges <- read.csv("../data/stormofswords.csv", stringsAsFactors=F)
str(edges)
library(igraph)
edges <- read.csv("../data/GOT-edges.csv", stringsAsFactors=F)
g <- graph_from_data_frame(d=edges, directed=FALSE)
g
plot(g)
sort(degree(g))
tail(sort(degree(g, mode="in"))) # number of times retweeted
tail(sort(degree(g, mode="out"))) # number of times retweeting
sort(degree(g))
tail(sort(degree(g, mode="in")))
tail(sort(degree(g, mode="out")))
head(sort(closeness(g, normalized=TRUE)))
head(sort(closeness(g)))
sort(closeness(g)
)
tail(sort(closeness(g, normalized=TRUE)))
head(sort(closeness(g, normalized=TRUE)))
tail(sort(betweenness(g)))
?closeness
g <- make_ring(10)
g2 <- make_star(10)
closeness(g)
closeness(g2, mode="in")
edge_density(g)
reciprocity(g)
transitivity(g)
g
library(igraph)
edges <- read.csv("../data/GOT-edges.csv", stringsAsFactors=F)
g <- graph_from_data_frame(d=edges, directed=FALSE)
transitivity(g)
reciprocity(g)
edge_density(g)
components(g)
comm <- cluster_infomap(g)
comm
comm[[1]]
comm[[2]]
comm[[3]]
comm[[7]]
comm[[6]]
comm[[5]]
comm[[4]]
coreness(g)
table(coreness(g))
which(coreness(g)==7) # what is the core of the network?
which(coreness(g)==6)
plot(g[coreness(g)==7])
?subgraph.edges
core <- subgraph(g, v=which(coreness(g)==7))
core <- induced_subgraph(g, v=which(coreness(g)==7))
core
plot(core)
library(rvest)
url <- "https://www.ssa.gov/oact/babynames/numberUSbirths.html"
html <- read_html(url) # reading the html code into memory
html # not very informative
substr(html_text(html), 1, 1000) # first 1000 characters
tab <- html_table(html, fill=TRUE)
str(tab)
pop <- tab[[2]]
pop <- tab[[1]]
pop
pop$Male <- as.numeric(gsub(",", "", pop$Male))
pop$Female <- as.numeric(gsub(",", "", pop$Female))
names(pop) <- c("year", "male", "female", "total")
plot(pop$year, pop$male, xlab="Year of birth", ylab="New SSN petitions",
col="darkgreen", type="l")
lines(pop$year, pop$female, col="red")
legend(x="topleft", c("Male", "Female"), lty=1, col=c("green", "red"))
plot(pop$year, pop$male, xlab="Year of birth", ylab="New SSN petitions",
col="darkgreen", type="l")
lines(pop$year, pop$female, col="red")
legend(x="topleft", c("Male", "Female"), lty=1, col=c("green", "red"))
url <- 'https://en.wikipedia.org/wiki/List_of_United_States_cities_by_population'
html <- read_html(url)
tables <- html_table(html, fill=TRUE)
length(tables)
wiki <- html_nodes(html, '.wikitable')
length(wiki)
pop <- html_table(wiki[[1]])
pop
pop <- html_table(wiki[[2]])
pop
str(pop)
pop$city_name <- gsub('\\[.*\\]', '', pop$City)
pop$population <- pop[,"2017estimate"]
pop$population <- as.numeric(gsub(",", "", pop$population))
pop$rank <- pop[,"2017rank"]
pop <- pop[,c("rank", "population", "city_name")]
pop <- html_table(wiki[[2]])
pop$city_name <- gsub('\\[.*\\]', '', pop$City)
pop$population <- pop[,"2018estimate"]
pop$population <- as.numeric(gsub(",", "", pop$population))
pop$rank <- pop[,"2018rank"]
pop <- pop[,c("rank", "population", "city_name")]
```
str(pop)
library(ggplot2)
p <- ggplot(pop, aes(x=rank, y=population, label=city_name))
pq <- p + geom_point() + geom_text(hjust=-.1, size=3) +
scale_x_log10("log(rank)") +
scale_y_log10("log(population)", labels=scales::comma) +
theme_minimal()
pq
lm(log(rank) ~ log(population), data=pop)
url <- 'http://ipaidabribe.com/reports/paid'
library(rvest, warn.conflicts=FALSE)
bribes <- read_html(url) # reading the HTML code
amounts <- html_nodes(bribes, ".paid-amount span") # identify the CSS selector
amounts # content of CSS selector
html_text(amounts)
transaction <- html_nodes(bribes, ".transaction a")
(transaction <- html_text(transaction))
# and one more
dept <- html_nodes(bribes, ".name a")
(dept <- html_text(dept))
scrape_bribe <- function(url){
bribes <- read_html(url)
# variables that we're interested in
amounts <- html_text(html_nodes(bribes, ".paid-amount span"))
amounts <- as.numeric(gsub("Paid INR | |\r|\n|,", "", amounts))
transaction <- html_text(html_nodes(bribes, ".transaction a"))
dept <- html_text(html_nodes(bribes, ".name a"))
# putting together into a data frame
df <- data.frame(
amounts = amounts,
transaction = transaction,
dept = dept,
stringsAsFactors=F)
return(df)
}
bribes <- list()
bribes[[1]] <- scrape_bribe(url)
str(bribes)
base_url <- "http://ipaidabribe.com/reports/paid?page="
pages <- seq(0, 40, by=10)
for (i in 2:length(pages)){
# informative message about progress of loop
message(i, '/', length(pages))
# prepare URL
url <- paste(base_url, pages[i], sep="")
# scrape website
bribes[[i]] <- scrape_bribe(url)
# wait a couple of seconds between URL calls
Sys.sleep(2)
}
bribes <- do.call(rbind, bribes)
head(bribes)
str(bribes)
tab <- table(bribes$transaction) # frequency table
tab <- sort(tab, decreasing=TRUE)	# sorting the table from most to least common
head(tab)
summary(bribes$amount)
agg <- aggregate(amount~dept, data=bribes, FUN=mean)
str(bribes)
agg <- aggregate(amounts~dept, data=bribes, FUN=mean)
agg[order(agg$amount, decreasing = TRUE),] # ordering from highest to
